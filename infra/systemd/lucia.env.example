# Lucia systemd Environment Configuration Template
# Installation: sudo cp lucia.env.example /etc/lucia/lucia.env
# Permissions: sudo chmod 600 /etc/lucia/lucia.env
# Edit: sudo nano /etc/lucia/lucia.env
#
# SECURITY WARNING: This file contains sensitive information.
# Ensure file permissions are set to 600 (read/write for owner only).
# Never commit this file with real credentials to version control.

# ============================================================================
# HOME ASSISTANT CONFIGURATION (REQUIRED)
# ============================================================================

# Base URL of your Home Assistant instance
# Format: http(s)://hostname:port
# Example: http://192.168.1.100:8123
HomeAssistant__BaseUrl=http://YOUR_HOME_ASSISTANT_IP:8123

# Long-lived access token from Home Assistant
# Create at: http://YOUR_HA_IP:8123/profile/security
# Token should start with "eyJ..." and be very long
# SENSITIVE: Keep this token secret!
HomeAssistant__AccessToken=YOUR_LONG_LIVED_ACCESS_TOKEN_HERE

# ============================================================================
# LLM PROVIDER CONFIGURATION (REQUIRED)
# ============================================================================

# API Key for your LLM provider
# - OpenAI: Starts with "sk-proj-..."
# - Azure OpenAI: Your Azure API key
# - Ollama (Local): Use "ollama" as the key
# - LM Studio (Local): Use "lm-studio" as the key
# SENSITIVE: Keep this key secret!
OpenAI__ApiKey=sk-proj-YOUR_OPENAI_KEY_HERE

# Base URL for OpenAI-compatible API
# - OpenAI: https://api.openai.com/v1
# - Azure OpenAI: https://YOUR_RESOURCE.openai.azure.com/
# - Ollama (Local): http://localhost:11434/v1
# - LM Studio (Local): http://localhost:1234/v1
OpenAI__BaseUrl=https://api.openai.com/v1

# Model identifier for chat completion
# - OpenAI: gpt-4o, gpt-4-turbo, gpt-3.5-turbo
# - Ollama: llama3.2, mistral, phi3
# - Azure: Your deployment name
OpenAI__ModelId=gpt-4o

# Model identifier for text embeddings (semantic search)
# - OpenAI: text-embedding-3-small, text-embedding-3-large
# - Ollama: mxbai-embed-large, nomic-embed-text
OpenAI__EmbeddingModelId=text-embedding-3-small

# ============================================================================
# REDIS CONFIGURATION (OPTIONAL)
# ============================================================================

# Redis server connection string
# Format: hostname:port
# Default: localhost:6379
# If Redis is on the same machine, use localhost:6379
Redis__ConnectionString=localhost:6379

# Redis authentication password (if required)
# Leave empty if Redis doesn't require authentication
# SENSITIVE: Keep this password secret if set!
Redis__Password=

# ============================================================================
# LOGGING CONFIGURATION (OPTIONAL)
# ============================================================================

# Default log level for the application
# Options: Trace, Debug, Information, Warning, Error, Critical
# Recommended: Information (production), Debug (troubleshooting)
Logging__LogLevel__Default=Information

# Specific log levels for components (optional)
# Logging__LogLevel__Microsoft=Warning
# Logging__LogLevel__Microsoft.AspNetCore=Warning
# Logging__LogLevel__lucia=Information

# ============================================================================
# ASPNETCORE CONFIGURATION (OPTIONAL)
# ============================================================================

# Application listening URLs
# Default: http://localhost:8080 (set by systemd service)
# Uncomment to override:
# ASPNETCORE_URLS=http://localhost:8080

# Environment (Development, Staging, Production)
# Default: Production
# ASPNETCORE_ENVIRONMENT=Production

# ============================================================================
# EXAMPLE CONFIGURATIONS FOR DIFFERENT LLM PROVIDERS
# ============================================================================

# --- OPENAI (CLOUD) ---
# OpenAI__ApiKey=sk-proj-abc123...
# OpenAI__BaseUrl=https://api.openai.com/v1
# OpenAI__ModelId=gpt-4o
# OpenAI__EmbeddingModelId=text-embedding-3-small

# --- AZURE OPENAI (CLOUD) ---
# OpenAI__ApiKey=YOUR_AZURE_KEY
# OpenAI__BaseUrl=https://your-resource.openai.azure.com/
# OpenAI__ModelId=gpt-4
# OpenAI__EmbeddingModelId=text-embedding-ada-002

# --- OLLAMA (LOCAL) ---
# Installation: curl -fsSL https://ollama.ai/install.sh | sh
# Pull models: ollama pull llama3.2 && ollama pull mxbai-embed-large
# OpenAI__ApiKey=ollama
# OpenAI__BaseUrl=http://localhost:11434/v1
# OpenAI__ModelId=llama3.2
# OpenAI__EmbeddingModelId=mxbai-embed-large

# --- LM STUDIO (LOCAL) ---
# Download: https://lmstudio.ai/
# OpenAI__ApiKey=lm-studio
# OpenAI__BaseUrl=http://localhost:1234/v1
# OpenAI__ModelId=local-model
# OpenAI__EmbeddingModelId=local-embedding-model

# ============================================================================
# TROUBLESHOOTING
# ============================================================================

# If the service fails to start:
# 1. Check logs: sudo journalctl -u lucia -n 50 --no-pager
# 2. Verify Redis is running: systemctl status redis
# 3. Test Home Assistant connection: curl http://YOUR_HA_IP:8123/api/
# 4. Verify .NET runtime: dotnet --version (should be 10.0 RC1 or later)
# 5. Check file permissions: ls -la /etc/lucia/lucia.env (should be 600)

# For more help, see: /opt/lucia/README.md or
# https://github.com/seiggy/lucia-dotnet/tree/main/infra/systemd
